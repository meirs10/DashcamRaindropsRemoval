{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Per-Frame Crapification Pipeline\n",
                "\n",
                "## Overview\n",
                "This notebook implements the data generation pipelineâ€”affectionately termed **\"Crapification\"**â€”for the training and validation datasets. The goal is to synthetically degrade clean images with realistic rain, fog, and water droplets to create a robust dataset for training the raindrops removal model.\n",
                "\n",
                "## Pipeline Stages\n",
                "For each scene and camera angle, the pipeline performs the following steps:\n",
                "1.  **Clean Baseline**: Copies the original clean images.\n",
                "2.  **Fog Generation**: Applies depth-based fog using a transmission map derived from the scene's depth data.\n",
                "3.  **Rain Streaks**: Overlays rain streaks, masking them based on depth to ensure they appear correctly behind objects.\n",
                "4.  **Compositing**: Blends the fog and rain layers with the original image.\n",
                "5.  **Water Droplets**: Generates randomized water droplets on the \"camera lens\" (simulated) to mimic real-world dashcam conditions.\n",
                "\n",
                "**Note:** This notebook mirrors the logic of `per_frame_crapification_pipeline.py`. It uses **randomized** droplet generation suitable for training data, ensuring the model learns to handle various droplet patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "\n",
                "# Set Project Root\n",
                "current_dir = Path.cwd()\n",
                "if current_dir.name == 'crapification':\n",
                "    BASE = current_dir.parent\n",
                "    # config files are local to crapification/\n",
                "    CONFIG_DIR = current_dir\n",
                "else:\n",
                "    BASE = current_dir\n",
                "    CONFIG_DIR = BASE / \"crapification\"\n",
                "\n",
                "sys.path.insert(0, str(BASE))\n",
                "print(f'Project Root: {BASE}')\n",
                "\n",
                "# Import from crapification package\n",
                "from crapification.stages_crapification.stage_fog import run_fog_stage\n",
                "from crapification.stages_crapification.stage_rain_masks import run_rain_mask_stage\n",
                "from crapification.stages_crapification.stage_composite import run_composite_stage\n",
                "from crapification.stages_crapification.stage_droplets import run_droplet_stage\n",
                "from crapification.stages_crapification.generate_depth import generate_depth_for_scene\n",
                "from crapification.helpers.scene_configurations import (\n",
                "    generate_scene_configurations,\n",
                "    load_configurations,\n",
                "    save_configurations,\n",
                "    print_configuration_summary\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration and Parameters\n",
                "\n",
                "Here we define the paths for input/output data and the intensity parameters for the degradation effects.\n",
                "\n",
                "- **`DATA_DIR`**: Source of original clean images and depth maps.\n",
                "- **`OUTPUT_BASE`**: Destination for the generated training data.\n",
                "- **`FOG_PARAMS`**: Controls the density and airlight of the fog simulation.\n",
                "- **`RAIN_PARAMS`**: dictating the density and length of rain streaks.\n",
                "- **`DROPLET_PARAMS`**: Controls the number of large and medium droplets on the lens."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =======================\n",
                "# PATH CONFIG\n",
                "# =======================\n",
                "DATA_DIR = BASE / \"data\" / \"data_original\"\n",
                "OUTPUT_BASE = BASE / \"data\" / \"data_crapified_train\"\n",
                "\n",
                "# Helpers are in crapification/helpers/\n",
                "HELPERS_DIR = CONFIG_DIR / \"helpers\"\n",
                "\n",
                "CONFIG_FILE = HELPERS_DIR / \"scene_intensity_configs.json\"\n",
                "SPLIT_FILE = HELPERS_DIR / \"scene_split.json\"\n",
                "PROGRESS_FILE = CONFIG_DIR / \"pipeline_progress.json\"\n",
                "\n",
                "TEXTURE_DIR = BASE / \"crapification\" / \"rain-rendering\" / \"rainstreakdb\"\n",
                "\n",
                "# Camera angles\n",
                "ANGLES = [\n",
                "    'front-forward',\n",
                "    'left-backward',\n",
                "    'left-forward',\n",
                "    'right-backward',\n",
                "    'right-forward'\n",
                "]\n",
                "\n",
                "# =======================\n",
                "# INTENSITY PARAMETERS\n",
                "# =======================\n",
                "FOG_PARAMS = {\n",
                "    'none': {'fog_density': 0.0, 'airlight': 255},\n",
                "    'light': {'fog_density': 0.02, 'airlight': 240},\n",
                "    'medium': {'fog_density': 0.06, 'airlight': 230},\n",
                "    'heavy': {'fog_density': 0.12, 'airlight': 220}\n",
                "}\n",
                "\n",
                "RAIN_PARAMS = {\n",
                "    'none': {'density': 0, 'min_length': 0, 'max_length': 0},\n",
                "    'light': {'density': 1000, 'min_length': 8, 'max_length': 20},\n",
                "    'medium': {'density': 2500, 'min_length': 8, 'max_length': 35},\n",
                "    'heavy': {'density': 4000, 'min_length': 15, 'max_length': 50}\n",
                "}\n",
                "\n",
                "DROPLET_PARAMS = {\n",
                "    'light': {'n_large': 10, 'n_medium': 18},\n",
                "    'medium': {'n_large': 16, 'n_medium': 28},\n",
                "    'heavy': {'n_large': 28, 'n_medium': 45},\n",
                "    'extreme': {'n_large': 40, 'n_medium': 60}\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper Functions\n",
                "\n",
                "The following functions handle the orchestration of the pipeline:\n",
                "\n",
                "- **`get_train_val_scenes()`**: Loads the list of scenes allocated for training and validation from the split file.\n",
                "- **`process_scene_angle()`**: The core worker function. It takes a single scene angle and executes the 5-stage pipeline (Clean -> Fog -> Rain -> Composite -> Droplets).\n",
                "- **`ProgressTracker`**: A utility class to resume processing from where it left off in case of interruptions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_train_val_scenes():\n",
                "    \"\"\"Load train+val scenes from scene_split.json\"\"\"\n",
                "    if SPLIT_FILE.exists():\n",
                "        print(f\"ðŸ“‹ Loading scene split from: {SPLIT_FILE}\")\n",
                "        with open(SPLIT_FILE, 'r') as f:\n",
                "            split_info = json.load(f)\n",
                "\n",
                "        train_scenes = split_info['train']\n",
                "        val_scenes = split_info['val']\n",
                "        train_val_scenes = sorted(train_scenes + val_scenes)\n",
                "\n",
                "        print(f\"   Train scenes: {len(train_scenes)}\")\n",
                "        print(f\"   Val scenes: {len(val_scenes)}\")\n",
                "        print(f\"   Total to process: {len(train_val_scenes)}\")\n",
                "        print(f\"   Test scenes (EXCLUDED): {len(split_info['test'])}\")\n",
                "\n",
                "        return train_val_scenes\n",
                "\n",
                "    else:\n",
                "        print(\"âš ï¸  scene_split.json not found!\")\n",
                "        print(\"   Run determine_split.py first!\")\n",
                "        return []\n",
                "\n",
                "\n",
                "class ProgressTracker:\n",
                "    def __init__(self):\n",
                "        self.progress_file = PROGRESS_FILE\n",
                "        self.progress = self.load_progress()\n",
                "\n",
                "    def load_progress(self):\n",
                "        if self.progress_file.exists():\n",
                "            with open(self.progress_file, 'r') as f:\n",
                "                return json.load(f)\n",
                "        return {'completed': [], 'last_scene': None, 'last_angle': None}\n",
                "\n",
                "    def save_progress(self):\n",
                "        with open(self.progress_file, 'w') as f:\n",
                "            json.dump(self.progress, f, indent=2)\n",
                "\n",
                "    def is_completed(self, scene, angle):\n",
                "        key = f\"{scene}_{angle}\"\n",
                "        return key in self.progress['completed']\n",
                "\n",
                "    def mark_completed(self, scene, angle):\n",
                "        key = f\"{scene}_{angle}\"\n",
                "        if key not in self.progress['completed']:\n",
                "            self.progress['completed'].append(key)\n",
                "        self.progress['last_scene'] = scene\n",
                "        self.progress['last_angle'] = angle\n",
                "        self.save_progress()\n",
                "\n",
                "    def get_status(self):\n",
                "        return len(self.progress['completed'])\n",
                "\n",
                "\n",
                "def copy_clean_images(src, dst):\n",
                "    Path(dst).mkdir(parents=True, exist_ok=True)\n",
                "    count = 0\n",
                "    for f in os.listdir(src):\n",
                "        if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
                "            shutil.copy2(\n",
                "                os.path.join(src, f),\n",
                "                os.path.join(dst, f)\n",
                "            )\n",
                "            count += 1\n",
                "    return count\n",
                "\n",
                "\n",
                "def ensure_depth_exists(scene_name, angle):\n",
                "    depth_dir = DATA_DIR / scene_name / \"depth\" / angle\n",
                "    img_dir = DATA_DIR / scene_name / \"images\" / angle\n",
                "\n",
                "    if not img_dir.exists():\n",
                "        print(f\"  âš ï¸  Images not found: {img_dir}\")\n",
                "        return False\n",
                "\n",
                "    if depth_dir.exists():\n",
                "        depth_files = [f for f in os.listdir(depth_dir) if f.lower().endswith('.png')]\n",
                "    else:\n",
                "        depth_files = []\n",
                "\n",
                "    img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
                "\n",
                "    if len(depth_files) == len(img_files) and len(depth_files) > 0:\n",
                "        print(f\"  âœ“ Depth exists ({len(depth_files)} files)\")\n",
                "        return True\n",
                "\n",
                "    print(f\"  ðŸ” Depth missing - generating...\")\n",
                "    success = generate_depth_for_scene(scene_name, angle, str(BASE))\n",
                "    return success\n",
                "\n",
                "\n",
                "def process_scene_angle(scene_name, angle, temp_dir, output_dir, intensity_config):\n",
                "    \"\"\"Process a single scene+angle with random droplets\"\"\"\n",
                "    scene_dir = DATA_DIR / scene_name\n",
                "    img_dir = scene_dir / \"images\" / angle\n",
                "    depth_dir = scene_dir / \"depth\" / angle\n",
                "\n",
                "    if not img_dir.exists():\n",
                "        print(f\"  âš ï¸  Images not found: {img_dir}\")\n",
                "        return 0\n",
                "\n",
                "    if not ensure_depth_exists(scene_name, angle):\n",
                "        print(f\"  âŒ Failed to generate depth maps\")\n",
                "        return 0\n",
                "\n",
                "    # Temp directories\n",
                "    clean_dir = temp_dir / \"00_clean\"\n",
                "    fog_dir = temp_dir / \"01_fog\"\n",
                "    rain_mask_dir = temp_dir / \"02_rain_masks\"\n",
                "    rain_dir = temp_dir / \"03_rain\"\n",
                "\n",
                "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    fog_intensity = intensity_config['fog']\n",
                "    rain_intensity = intensity_config['rain']\n",
                "    droplet_intensity = intensity_config['droplets']\n",
                "\n",
                "    print(f\"  ðŸŽ¨ Config: Fog={fog_intensity}, Rain={rain_intensity}, Droplets={droplet_intensity} (RANDOM)\")\n",
                "\n",
                "    try:\n",
                "        # 0ï¸âƒ£ Copy clean\n",
                "        print(\"  [0] Copying clean...\")\n",
                "        num_images = copy_clean_images(img_dir, clean_dir)\n",
                "        if num_images == 0:\n",
                "            return 0\n",
                "\n",
                "        # 1ï¸âƒ£ Fog\n",
                "        fog_params = FOG_PARAMS[fog_intensity]\n",
                "        print(f\"  [1] Fog ({fog_intensity})...\")\n",
                "        run_fog_stage(\n",
                "            img_dir=str(clean_dir),\n",
                "            depth_dir=str(depth_dir),\n",
                "            output_dir=str(fog_dir),\n",
                "            fog_density=fog_params['fog_density'],\n",
                "            airlight=fog_params['airlight']\n",
                "        )\n",
                "\n",
                "        # 2ï¸âƒ£ Rain masks\n",
                "        rain_params = RAIN_PARAMS[rain_intensity]\n",
                "        print(f\"  [2] Rain masks ({rain_intensity})...\")\n",
                "        run_rain_mask_stage(\n",
                "            depth_dir=str(depth_dir),\n",
                "            texture_dir=str(TEXTURE_DIR),\n",
                "            output_dir=str(rain_mask_dir),\n",
                "            rain_density=rain_params['density'],\n",
                "            min_length=rain_params['min_length'],\n",
                "            max_length=rain_params['max_length']\n",
                "        )\n",
                "\n",
                "        # 3ï¸âƒ£ Composite\n",
                "        print(\"  [3] Compositing...\")\n",
                "        run_composite_stage(\n",
                "            fog_dir=str(fog_dir),\n",
                "            rain_dir=str(rain_mask_dir),\n",
                "            output_dir=str(rain_dir),\n",
                "            rain_brightness=0.4\n",
                "        )\n",
                "\n",
                "        # 4ï¸âƒ£ Random droplets\n",
                "        print(f\"  [4] Droplets ({droplet_intensity}, RANDOM)...\")\n",
                "        run_droplet_stage(\n",
                "            input_dir=str(rain_dir),\n",
                "            output_dir=str(output_dir),\n",
                "            mask_dir=None,\n",
                "            seed=hash(f\"{scene_name}_{angle}\") % 10000,\n",
                "            intensity=droplet_intensity,\n",
                "            use_gpu=True,\n",
                "            persistent=False\n",
                "        )\n",
                "\n",
                "        print(f\"  âœ“ Processed {num_images} images\")\n",
                "        return num_images\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"  âŒ Error: {str(e)}\")\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "        return 0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Execution\n",
                "\n",
                "This section kicks off the pipeline. It:\n",
                "1.  Checks for an existing scene configuration file or generates a new one.\n",
                "2.  Iterates through every Train/Val scene and angle.\n",
                "3.  Skips already completed scenes (thanks to `ProgressTracker`).\n",
                "4.  Calls `process_scene_angle` to generate the data.\n",
                "5.  Cleans up temporary directories to save space."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def main():\n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    print(\"TRAINING DATA CRAPIFICATION PIPELINE\")\n",
                "    print(\"(TRAIN + VAL SCENES ONLY)\")\n",
                "    print(\"=\" * 60 + \"\\n\")\n",
                "\n",
                "    train_val_scenes = get_train_val_scenes()\n",
                "\n",
                "    if not train_val_scenes:\n",
                "        print(\"âŒ No scenes to process!\")\n",
                "        return\n",
                "\n",
                "    total_combinations = len(train_val_scenes) * len(ANGLES)\n",
                "\n",
                "    # Load configs\n",
                "    if CONFIG_FILE.exists():\n",
                "        print(\"\\nðŸ“‹ Loading scene configurations...\")\n",
                "        scene_configs = load_configurations(str(CONFIG_FILE))\n",
                "    else:\n",
                "        print(\"\\nðŸŽ² Generating scene configurations...\")\n",
                "        # You might need to adjust seed or logic if you want different configs\n",
                "        scene_configs = generate_scene_configurations(num_scenes=101, seed=42)\n",
                "        save_configurations(scene_configs, str(CONFIG_FILE))\n",
                "\n",
                "    print_configuration_summary(scene_configs)\n",
                "\n",
                "    tracker = ProgressTracker()\n",
                "\n",
                "    print(f\"\\nScenes to process: {len(train_val_scenes)} (train+val)\")\n",
                "    print(f\"Angles per scene: {len(ANGLES)}\")\n",
                "    print(f\"Total combinations: {total_combinations}\")\n",
                "    print(f\"Already completed: {tracker.get_status()}\")\n",
                "    print(f\"\\n{'=' * 60}\\n\")\n",
                "\n",
                "    start_time = datetime.now()\n",
                "    total_images = 0\n",
                "\n",
                "    temp_base = BASE / \"temp_pipeline\"\n",
                "\n",
                "    for scene_num in train_val_scenes:\n",
                "        scene_name = f\"scene_{scene_num:03d}\"\n",
                "        intensity_config = scene_configs[scene_num]\n",
                "\n",
                "        for angle in ANGLES:\n",
                "            if tracker.is_completed(scene_name, angle):\n",
                "                print(f\"âœ“ Skipping {scene_name}/{angle} (completed)\")\n",
                "                continue\n",
                "\n",
                "            print(f\"\\n{'=' * 60}\")\n",
                "            print(f\"Processing: {scene_name}/{angle} (TRAIN/VAL)\")\n",
                "            print(f\"{'=' * 60}\")\n",
                "\n",
                "            temp_dir = temp_base / f\"{scene_name}_{angle}\"\n",
                "            temp_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "            output_dir = OUTPUT_BASE / scene_name / angle\n",
                "\n",
                "            num_images = process_scene_angle(\n",
                "                scene_name, angle, temp_dir, output_dir, intensity_config\n",
                "            )\n",
                "\n",
                "            if num_images > 0:\n",
                "                total_images += num_images\n",
                "                tracker.mark_completed(scene_name, angle)\n",
                "\n",
                "            try:\n",
                "                shutil.rmtree(temp_dir)\n",
                "            except:\n",
                "                pass\n",
                "\n",
                "            completed = tracker.get_status()\n",
                "            percent = (completed / total_combinations) * 100\n",
                "            print(f\"\\nðŸ“Š Progress: {completed}/{total_combinations} ({percent:.1f}%)\")\n",
                "\n",
                "    try:\n",
                "        shutil.rmtree(temp_base)\n",
                "    except:\n",
                "        pass\n",
                "\n",
                "    duration = datetime.now() - start_time\n",
                "\n",
                "    print(f\"\\n{'=' * 60}\")\n",
                "    print(\"PIPELINE COMPLETE!\")\n",
                "    print(f\"{'=' * 60}\")\n",
                "    print(f\"Time: {duration}\")\n",
                "    print(f\"Images: {total_images}\")\n",
                "    print(f\"Output: {OUTPUT_BASE}\")\n",
                "    print(f\"{'=' * 60}\\n\")\n",
                "\n",
                "main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
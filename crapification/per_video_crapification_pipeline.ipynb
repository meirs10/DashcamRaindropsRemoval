{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Video Crapification Pipeline (Persistent Droplets)\n",
    "\n",
    "## Overview\n",
    "This notebook focuses on generating the **Test Set** data. Unlike the training set generation (where droplets are randomized), this pipeline generates **persistent droplets** that remain consistent across a video sequence.\n",
    "\n",
    "## Pipeline Stages\n",
    "For each video and camera angle, the pipeline performs the following steps:\n",
    "1.  **Clean Baseline**: Copies the original clean images.\n",
    "2.  **Fog Generation**: Applies depth-based fog using a transmission map derived from the scene's depth data.\n",
    "3.  **Rain Streaks**: Overlays rain streaks, masking them based on depth to ensure they appear correctly behind objects.\n",
    "4.  **Compositing**: Blends the fog and rain layers with the original image.\n",
    "5.  **Water Droplets**: Generates persistent water droplets on the \"camera lens\" (simulated) to mimic real-world dashcam conditions."
   ],
   "id": "7402c859807dbf5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Set Project Root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'crapification':\n",
    "    BASE = current_dir.parent\n",
    "    CONFIG_DIR = current_dir\n",
    "else:\n",
    "    BASE = current_dir\n",
    "    CONFIG_DIR = BASE / \"crapification\"\n",
    "\n",
    "sys.path.insert(0, str(BASE))\n",
    "print(f'Project Root: {BASE}')\n",
    "\n",
    "# Import from crapification\n",
    "from crapification.stages_crapification.stage_fog import run_fog_stage\n",
    "from crapification.stages_crapification.stage_rain_masks import run_rain_mask_stage\n",
    "from crapification.stages_crapification.stage_composite import run_composite_stage\n",
    "from crapification.stages_crapification.stage_droplets import run_droplet_stage\n",
    "from crapification.stages_crapification.generate_depth import generate_depth_for_scene\n",
    "from crapification.helpers.scene_configurations import load_configurations"
   ],
   "id": "d48225fe86f43e6a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- **`SPLIT_GROUP`**: Set to `\"test\"` to ensure we only process the withheld test scenes.\n",
    "- **`OUTPUT_BASE`**: Data is saved to `data/data_crapified_test`.\n",
    "- **Degradation Parameters**: Same dictionary definitions as the training pipeline to ensure consistent intensity levels (Fog, Rain, Droplets)."
   ],
   "id": "274915415e17b8a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# PATH CONFIG\n",
    "# =======================\n",
    "DATA_DIR = BASE / \"data\" / \"data_original\"\n",
    "OUTPUT_BASE = BASE / \"data\" / \"data_crapified_test\"\n",
    "\n",
    "HELPERS_DIR = CONFIG_DIR / \"helpers\"\n",
    "CONFIG_FILE = HELPERS_DIR / \"scene_intensity_configs.json\"\n",
    "SPLIT_FILE = HELPERS_DIR / \"scene_split.json\"\n",
    "\n",
    "# Correctly targeting the test split\n",
    "SPLIT_GROUP = \"test\"\n",
    "\n",
    "TEXTURE_DIR = BASE / \"crapification\" / \"rain-rendering\" / \"rainstreakdb\"\n",
    "\n",
    "ANGLES = [\n",
    "    'front-forward',\n",
    "    'left-backward',\n",
    "    'left-forward',\n",
    "    'right-backward',\n",
    "    'right-forward'\n",
    "]\n",
    "\n",
    "# =======================\n",
    "# INTENSITY PARAMETERS\n",
    "# =======================\n",
    "FOG_PARAMS = {\n",
    "    'none': {'fog_density': 0.0, 'airlight': 255},\n",
    "    'light': {'fog_density': 0.02, 'airlight': 240},\n",
    "    'medium': {'fog_density': 0.06, 'airlight': 230},\n",
    "    'heavy': {'fog_density': 0.12, 'airlight': 220}\n",
    "}\n",
    "\n",
    "RAIN_PARAMS = {\n",
    "    'none': {'density': 0, 'min_length': 0, 'max_length': 0},\n",
    "    'light': {'density': 1000, 'min_length': 8, 'max_length': 20},\n",
    "    'medium': {'density': 2500, 'min_length': 8, 'max_length': 35},\n",
    "    'heavy': {'density': 4000, 'min_length': 15, 'max_length': 50}\n",
    "}"
   ],
   "id": "a54ee558d444043f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "- **`get_scene_numbers`**: Helper to extract specific split groups from the JSON file.\n",
    "- **`process_test_scene_angle`**: The worker function. Critically, it calls `run_droplet_stage` with `persistent=True`."
   ],
   "id": "77fdb1dbd1e617a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene_numbers(split_group):\n",
    "    \"\"\"Load test scenes from scene_split.json\"\"\"\n",
    "    if not SPLIT_FILE.exists():\n",
    "        print(f\"âŒ Split file not found: {SPLIT_FILE}\")\n",
    "        print(\"   Run determine_split.py first!\")\n",
    "        return []\n",
    "\n",
    "    with open(SPLIT_FILE, 'r') as f:\n",
    "        split_info = json.load(f)\n",
    "\n",
    "    return split_info[split_group]\n",
    "\n",
    "\n",
    "def copy_clean_images(src, dst):\n",
    "    Path(dst).mkdir(parents=True, exist_ok=True)\n",
    "    count = 0\n",
    "    for f in os.listdir(src):\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            shutil.copy2(\n",
    "                os.path.join(src, f),\n",
    "                os.path.join(dst, f)\n",
    "            )\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def ensure_depth_exists(scene_name, angle):\n",
    "    depth_dir = DATA_DIR / scene_name / \"depth\" / angle\n",
    "    img_dir = DATA_DIR / scene_name / \"images\" / angle\n",
    "\n",
    "    if not img_dir.exists():\n",
    "        print(f\"  âš ï¸  Images not found: {img_dir}\")\n",
    "        return False\n",
    "\n",
    "    if depth_dir.exists():\n",
    "        depth_files = [f for f in os.listdir(depth_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    else:\n",
    "        depth_files = []\n",
    "\n",
    "    img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if len(depth_files) == len(img_files) and len(depth_files) > 0:\n",
    "        print(f\"  âœ“ Depth exists ({len(depth_files)} files)\")\n",
    "        return True\n",
    "\n",
    "    print(f\"  ðŸ” Generating depth...\")\n",
    "    success = generate_depth_for_scene(scene_name, angle, str(BASE))\n",
    "    return success\n",
    "\n",
    "\n",
    "def process_test_scene_angle(scene_name, angle, temp_dir, output_dir, intensity_config):\n",
    "    \"\"\"Process test scene with PERSISTENT droplets\"\"\"\n",
    "    scene_dir = DATA_DIR / scene_name\n",
    "    img_dir = scene_dir / \"images\" / angle\n",
    "    depth_dir = scene_dir / \"depth\" / angle\n",
    "\n",
    "    if not img_dir.exists():\n",
    "        print(f\"  âš ï¸  Images not found\")\n",
    "        return 0\n",
    "\n",
    "    if not ensure_depth_exists(scene_name, angle):\n",
    "        print(f\"  âŒ Depth generation failed\")\n",
    "        return 0\n",
    "\n",
    "    # Temp directories\n",
    "    clean_dir = temp_dir / \"00_clean\"\n",
    "    fog_dir = temp_dir / \"01_fog\"\n",
    "    rain_mask_dir = temp_dir / \"02_rain_masks\"\n",
    "    rain_dir = temp_dir / \"03_rain\"\n",
    "\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fog_intensity = intensity_config['fog']\n",
    "    rain_intensity = intensity_config['rain']\n",
    "    droplet_intensity = intensity_config['droplets']\n",
    "\n",
    "    print(f\"  ðŸŽ¨ Config: Fog={fog_intensity}, Rain={rain_intensity}, Droplets={droplet_intensity} (PERSISTENT)\")\n",
    "\n",
    "    try:\n",
    "        # 0ï¸âƒ£ Copy clean\n",
    "        print(\"  [0] Copying clean...\")\n",
    "        num_images = copy_clean_images(img_dir, clean_dir)\n",
    "        if num_images == 0:\n",
    "            return 0\n",
    "\n",
    "        # 1ï¸âƒ£ Fog (depth-based, varies per frame - same as training)\n",
    "        fog_params = FOG_PARAMS[fog_intensity]\n",
    "        print(f\"  [1] Fog ({fog_intensity})...\")\n",
    "        run_fog_stage(\n",
    "            img_dir=str(clean_dir),\n",
    "            depth_dir=str(depth_dir),\n",
    "            output_dir=str(fog_dir),\n",
    "            fog_density=fog_params['fog_density'],\n",
    "            airlight=fog_params['airlight']\n",
    "        )\n",
    "\n",
    "        # 2ï¸âƒ£ Rain masks (same as training)\n",
    "        rain_params = RAIN_PARAMS[rain_intensity]\n",
    "        print(f\"  [2] Rain masks ({rain_intensity})...\")\n",
    "        run_rain_mask_stage(\n",
    "            depth_dir=str(depth_dir),\n",
    "            texture_dir=str(TEXTURE_DIR),\n",
    "            output_dir=str(rain_mask_dir),\n",
    "            rain_density=rain_params['density'],\n",
    "            min_length=rain_params['min_length'],\n",
    "            max_length=rain_params['max_length']\n",
    "        )\n",
    "\n",
    "        # 3ï¸âƒ£ Composite\n",
    "        print(\"  [3] Compositing...\")\n",
    "        run_composite_stage(\n",
    "            fog_dir=str(fog_dir),\n",
    "            rain_dir=str(rain_mask_dir),\n",
    "            output_dir=str(rain_dir),\n",
    "            rain_brightness=0.4\n",
    "        )\n",
    "\n",
    "        # 4ï¸âƒ£ PERSISTENT droplets (KEY DIFFERENCE!)\n",
    "        print(f\"  [4] PERSISTENT droplets ({droplet_intensity})...\")\n",
    "        run_droplet_stage(\n",
    "            input_dir=str(rain_dir),\n",
    "            output_dir=str(output_dir),\n",
    "            mask_dir=None,\n",
    "            seed=hash(f\"{scene_name}_{angle}\") % 10000,\n",
    "            intensity=droplet_intensity,\n",
    "            use_gpu=True,\n",
    "            persistent=True  # â† PERSISTENT for test set!\n",
    "        )\n",
    "\n",
    "        print(f\"  âœ“ Processed {num_images} images with persistent droplets\")\n",
    "        return num_images\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0"
   ],
   "id": "b2bc91b5085c1543"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "Executes the pipeline for all scenes in the test set."
   ],
   "id": "831e0426690e1dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"REALISTIC TEST SET PIPELINE\")\n",
    "    print(\"WITH PERSISTENT DROPLETS\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "    # Get scenes based on SPLIT_GROUP (strictly 'train' as per script, despite text)\n",
    "    scenes = get_scene_numbers(SPLIT_GROUP)\n",
    "\n",
    "    if not scenes:\n",
    "        print(\"âŒ No scenes found!\")\n",
    "        return\n",
    "\n",
    "    print(f\"ðŸ“‹ scenes (80/10/10 split):\")\n",
    "    print(f\"   Scenes: {scenes}\")\n",
    "    print(f\"   Count: {len(scenes)} scenes\")\n",
    "    print(f\"   Angles: {len(ANGLES)}\")\n",
    "    print(f\"   Total: {len(scenes) * len(ANGLES)} combinations\\n\")\n",
    "\n",
    "    # Load intensity configs\n",
    "    if not CONFIG_FILE.exists():\n",
    "        print(f\"âŒ Configuration file not found: {CONFIG_FILE}\")\n",
    "        print(\"   Run per_frame_crapification_pipeline.py first.\")\n",
    "        return\n",
    "\n",
    "    scene_configs = load_configurations(str(CONFIG_FILE))\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    total_images = 0\n",
    "    completed = 0\n",
    "    total_combinations = len(scenes) * len(ANGLES)\n",
    "\n",
    "    temp_base = BASE / \"temp_test_pipeline\"\n",
    "\n",
    "    # Process scenes\n",
    "    for scene_num in scenes:\n",
    "        scene_name = f\"scene_{scene_num:03d}\"\n",
    "        # Handle potential missing config key if splits changed\n",
    "        if scene_num not in scene_configs:\n",
    "                print(f\"âš ï¸  Config for scene {scene_num} not found. Skipping.\")\n",
    "                continue\n",
    "        \n",
    "        intensity_config = scene_configs[scene_num]\n",
    "\n",
    "        for angle in ANGLES:\n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"Processing: {scene_name}/{angle} (TEST - PERSISTENT)\")\n",
    "            print(f\"{'=' * 60}\")\n",
    "\n",
    "            temp_dir = temp_base / f\"{scene_name}_{angle}\"\n",
    "            temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            output_dir = OUTPUT_BASE / scene_name / angle\n",
    "\n",
    "            num_images = process_test_scene_angle(\n",
    "                scene_name, angle, temp_dir, output_dir, intensity_config\n",
    "            )\n",
    "\n",
    "            if num_images > 0:\n",
    "                total_images += num_images\n",
    "                completed += 1\n",
    "\n",
    "            try:\n",
    "                shutil.rmtree(temp_dir)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            percent = (completed / total_combinations) * 100\n",
    "            print(f\"\\nðŸ“Š Progress: {completed}/{total_combinations} ({percent:.1f}%)\")\n",
    "\n",
    "    # Cleanup\n",
    "    try:\n",
    "        shutil.rmtree(temp_base)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    duration = datetime.now() - start_time\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"TEST SET COMPLETE!\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Time: {duration}\")\n",
    "    print(f\"Images: {total_images}\")\n",
    "    print(f\"Completed: {completed}/{total_combinations}\")\n",
    "    print(f\"Output: {OUTPUT_BASE}\")\n",
    "    print(f\"\\nTest set created with PERSISTENT droplets\")\n",
    "    print(f\"Ready for model evaluation\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "main()"
   ],
   "id": "3b5bf2518868d4a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Inference Benchmark\n",
    "\n",
    "## Overview\n",
    "This notebook implements a **high-performance inference benchmark** for the Stage 2 model. Unlike the standard testing pipeline, this script is optimized to approximate real-time deployment conditions.\n",
    "\n",
    "## Key Optimizations\n",
    "- **Pre-Allocated GPU Buffers**: Accumulation and weight buffers (`acc_buffer`, `wgt_buffer`) are allocated once on the GPU to prevent memory fragmentation and allocation overhead per frame.\n",
    "- **GPU-Based Reconstruction**: The Hann-window weighted blending is performed entirely on the GPU using in-place operations (`add_`), significantly reducing CPU-GPU synchronization overhead.\n",
    "- **Pure Inference Timing**: The benchmark measures the core computational path (Forward Pass + GPU Reconstruction), differentiating it from I/O-bound tasks.\n",
    "- **Deferred I/O**: Video encoding and image saving occur *after* the benchmark loop to ensure the GPU runs without I/O interruptions."
   ],
   "id": "4b50ede185c6b798"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:24:29.052334Z",
     "start_time": "2026-02-15T09:23:58.020325Z"
    }
   },
   "source": [
    "import json\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from statistics import mean, median\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set Project Root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'testing':\n",
    "    BASE = current_dir.parent\n",
    "else:\n",
    "    BASE = current_dir\n",
    "\n",
    "sys.path.insert(0, str(BASE))\n",
    "print(f'Project Root: {BASE}')\n",
    "\n",
    "from training.helpers.model import MobileNetV3UNetConvLSTMVideo"
   ],
   "id": "b98452e119b0985b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: D:\\Pycharm Projects\\DashcamRaindropsRemoval\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "- **`TARGET_FPS`**: 33.0 (Real-time target).\n",
    "- **`ROWS/COLS`**: 3x5 tiling grid.\n",
    "- **`VIDEO_FPS`**: 10 (Playback speed for the output video)."
   ],
   "id": "7b66cd7aee34bbfd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:24:29.209917Z",
     "start_time": "2026-02-15T09:24:29.092228Z"
    }
   },
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Paths / Config\n",
    "# --------------------------------------------------------------------\n",
    "CHECKPOINT_PATH = BASE / \"training\" / \"checkpoints\" / \"stage2\" / \"best_stage2.pth\"\n",
    "\n",
    "RAINY_DIR = BASE / \"data\" / \"data_crapified_test\" / \"scene_015\" / \"front-forward\"\n",
    "CLEAN_DIR = BASE / \"data\" / \"data_original\" / \"scene_015\" / \"images\" / \"front-forward\"\n",
    "\n",
    "OUTPUT_DIR = BASE / \"testing\" / \"test_results\" / \"scene_004_inference_benchmark\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_FPS = 33.0\n",
    "TARGET_MS_PER_FRAME = 1000.0 / TARGET_FPS\n",
    "VIDEO_FPS = 10\n",
    "TILE = 512\n",
    "ROWS, COLS = 3, 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "19d8ce84f276abcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Helper Functions\n",
    "- **`load_frame_fullres`**: Loads and normalizes images (CPU).\n",
    "- **`make_hann_mask`**: Creates the 2D weighting mask. Note the `periodic=False` for correct windowing.\n",
    "- **`get_tile_coords`**: Computes standard overlapping grid coordinates."
   ],
   "id": "94d4b4206b2cff0a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:24:29.225140Z",
     "start_time": "2026-02-15T09:24:29.214922Z"
    }
   },
   "source": [
    "def load_frame_fullres(path: Path) -> torch.Tensor:\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return torch.from_numpy(img).permute(2, 0, 1).float().div(255.0)\n",
    "\n",
    "\n",
    "def get_tile_coords(h, w, tile=512, rows=3, cols=5):\n",
    "    xs = np.linspace(0, w - tile, cols).round().astype(int).tolist()\n",
    "    ys = np.linspace(0, h - tile, rows).round().astype(int).tolist()\n",
    "    return [(y, x) for y in ys for x in xs]\n",
    "\n",
    "\n",
    "def make_hann_mask(tile, device):\n",
    "    w1 = torch.hann_window(tile, periodic=False, device=device)\n",
    "    return torch.outer(w1, w1).clamp_min(1e-4).unsqueeze(0)\n",
    "\n",
    "\n",
    "def chw_to_bgr_uint8(chw: torch.Tensor) -> np.ndarray:\n",
    "    return cv2.cvtColor((chw.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)"
   ],
   "id": "8012f845d237385d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "### Pipeline Steps:\n",
    "1.  **Setup**: Loads model and pre-calculates tile coordinates.\n",
    "2.  **Pre-Allocation**: Creates `acc_buffer` and `wgt_buffer` on the GPU *before* the loop. This is critical for performance.\n",
    "3.  **Benchmark Loop**:\n",
    "    -   **Load**: Prepare tiles (CPU).\n",
    "    -   **Transfer**: Move tile batch to GPU.\n",
    "    -   **Inference**: Run model (`forward`).\n",
    "    -   **Reconstruct**: Accumulate weighted tiles into the buffers using GPU ops.\n",
    "    -   **Normalize**: Divide accumulation by weight map.\n",
    "4.  **Save Results**: After the timing loop is done, iterate through the buffer to save the video and images."
   ],
   "id": "d57e0faf3ef9eb1a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:30:12.770567Z",
     "start_time": "2026-02-15T09:24:29.232099Z"
    }
   },
   "source": [
    "def main():\n",
    "    print(f\"Using device: {device}\")\n",
    "    if not CHECKPOINT_PATH.exists():\n",
    "         raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n",
    "\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model = MobileNetV3UNetConvLSTMVideo(hidden_dim=96, out_channels=3).to(device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    rainy_files = sorted(RAINY_DIR.glob(\"*.jpeg\"))\n",
    "    clean_files = sorted(CLEAN_DIR.glob(\"*.jpeg\"))\n",
    "    n = min(len(rainy_files), len(clean_files))\n",
    "    if n == 0:\n",
    "        print(\"No frames found!\")\n",
    "        return\n",
    "\n",
    "    # Pre-probe dimensions\n",
    "    tmp_img = cv2.imread(str(rainy_files[0]))\n",
    "    h, w, _ = tmp_img.shape\n",
    "    coords = get_tile_coords(h, w, TILE, ROWS, COLS)\n",
    "    hann_mask = make_hann_mask(TILE, device)\n",
    "\n",
    "    # PRE-ALLOCATE GPU BUFFERS (Critical to prevent fragmentation)\n",
    "    acc_buffer = torch.zeros((3, h, w), device=device)\n",
    "    wgt_buffer = torch.zeros((1, h, w), device=device)\n",
    "\n",
    "    times_ms = []\n",
    "    processed_frames = []\n",
    "\n",
    "    print(f\"\\nStarting Optimized Benchmark ({n} frames)...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            # 1. Load data (CPU)\n",
    "            rainy_chw = load_frame_fullres(rainy_files[i])\n",
    "            clean_chw = load_frame_fullres(clean_files[i])\n",
    "\n",
    "            # 2. Build Tile Batch\n",
    "            tiles = torch.stack([rainy_chw[:, y:y + TILE, x:x + TILE] for y, x in coords]).to(device)\n",
    "\n",
    "            # --- START TIMING ---\n",
    "            if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "            t0 = time.perf_counter()\n",
    "\n",
    "            # 3. Model Forward\n",
    "            out_tiles = model(tiles.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            # 4. Weighted Reconstruct (on GPU)\n",
    "            acc_buffer.zero_()\n",
    "            wgt_buffer.zero_()\n",
    "            for idx, (y, x) in enumerate(coords):\n",
    "                tile_out = out_tiles[idx]\n",
    "                acc_buffer[:, y:y + TILE, x:x + TILE].add_(tile_out * hann_mask)\n",
    "                wgt_buffer[:, y:y + TILE, x:x + TILE].add_(hann_mask)\n",
    "\n",
    "            out_full = acc_buffer / wgt_buffer.clamp_min(1e-6)\n",
    "\n",
    "            if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "            dt_ms = (time.perf_counter() - t0) * 1000.0\n",
    "            # --- END TIMING ---\n",
    "\n",
    "            times_ms.append(dt_ms)\n",
    "\n",
    "            # Post-processing (Moving to CPU to free GPU ASAP)\n",
    "            out_cpu = out_full.clamp(0, 1).cpu()\n",
    "            processed_frames.append((rainy_chw, out_cpu, clean_chw, dt_ms))\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Frame {i}/{n}: {dt_ms:.2f}ms ({1000 / dt_ms:.1f} FPS)\")\n",
    "\n",
    "    # --------------------------------------------------------------------\n",
    "    # IO Section (Save results after benchmark is done)\n",
    "    # --------------------------------------------------------------------\n",
    "    print(\"\\nBenchmark finished. Saving video and images...\")\n",
    "    video_path = OUTPUT_DIR / \"comparison_video.mp4\"\n",
    "    writer = cv2.VideoWriter(str(video_path), cv2.VideoWriter_fourcc(*\"mp4v\"), VIDEO_FPS, (w, h * 3))\n",
    "\n",
    "    for i, (r_chw, o_chw, c_chw, dt) in enumerate(processed_frames):\n",
    "        r_bgr = chw_to_bgr_uint8(r_chw)\n",
    "        o_bgr = chw_to_bgr_uint8(o_chw)\n",
    "        c_bgr = chw_to_bgr_uint8(c_chw)\n",
    "\n",
    "        stacked = np.concatenate([r_bgr, o_bgr, c_bgr], axis=0)\n",
    "\n",
    "        # Overlay labels\n",
    "        fps = 1000.0 / dt if dt > 0 else 0\n",
    "        cv2.putText(stacked, f\"{dt:.1f}ms | {fps:.1f} FPS\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        writer.write(stacked)\n",
    "        if i < 10:  # Only save first few as images to save space\n",
    "            cv2.imwrite(str(OUTPUT_DIR / f\"frame_{i:03d}.png\"), stacked)\n",
    "\n",
    "    writer.release()\n",
    "\n",
    "    # Summary\n",
    "    avg_ms = mean(times_ms)\n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    print(f\"AVERAGE LATENCY: {avg_ms:.2f} ms\")\n",
    "    print(f\"AVERAGE FPS:     {1000 / avg_ms:.2f}\")\n",
    "    print(f\"MEETS TARGET:    {avg_ms <= TARGET_MS_PER_FRAME}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "main()"
   ],
   "id": "b6a58be89aa0b024",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ofiri\\AppData\\Local\\Temp\\ipykernel_16444\\3285440737.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
      "C:\\Users\\ofiri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ofiri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Encoder frozen (weights + BatchNorm running stats)\n",
      "\n",
      "Starting Optimized Benchmark (200 frames)...\n",
      "Frame 0/200: 534.09ms (1.9 FPS)\n",
      "Frame 10/200: 66.41ms (15.1 FPS)\n",
      "Frame 20/200: 71.09ms (14.1 FPS)\n",
      "Frame 30/200: 65.77ms (15.2 FPS)\n",
      "Frame 40/200: 66.92ms (14.9 FPS)\n",
      "Frame 50/200: 67.31ms (14.9 FPS)\n",
      "Frame 60/200: 67.12ms (14.9 FPS)\n",
      "Frame 70/200: 66.71ms (15.0 FPS)\n",
      "Frame 80/200: 72.08ms (13.9 FPS)\n",
      "Frame 90/200: 72.99ms (13.7 FPS)\n",
      "Frame 100/200: 71.84ms (13.9 FPS)\n",
      "Frame 110/200: 70.00ms (14.3 FPS)\n",
      "Frame 120/200: 78.87ms (12.7 FPS)\n",
      "Frame 130/200: 231.76ms (4.3 FPS)\n",
      "Frame 140/200: 70.42ms (14.2 FPS)\n",
      "Frame 150/200: 71.75ms (13.9 FPS)\n",
      "Frame 160/200: 99.74ms (10.0 FPS)\n",
      "Frame 170/200: 79.78ms (12.5 FPS)\n",
      "Frame 180/200: 69.37ms (14.4 FPS)\n",
      "Frame 190/200: 72.91ms (13.7 FPS)\n",
      "\n",
      "Benchmark finished. Saving video and images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

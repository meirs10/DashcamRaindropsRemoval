{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Optimized Inference Benchmark\n",
                "\n",
                "## Overview\n",
                "This notebook implements a **high-performance inference benchmark** for the Stage 2 model. Unlike the standard testing pipeline, this script is optimized to approximate real-time deployment conditions.\n",
                "\n",
                "## Key Optimizations\n",
                "- **Pre-Allocated GPU Buffers**: Accumulation and weight buffers (`acc_buffer`, `wgt_buffer`) are allocated once on the GPU to prevent memory fragmentation and allocation overhead per frame.\n",
                "- **GPU-Based Reconstruction**: The Hann-window weighted blending is performed entirely on the GPU using in-place operations (`add_`), significantly reducing CPU-GPU synchronization overhead.\n",
                "- **Pure Inference Timing**: The benchmark measures the core computational path (Forward Pass + GPU Reconstruction), differentiating it from I/O-bound tasks.\n",
                "- **Deferred I/O**: Video encoding and image saving occur *after* the benchmark loop to ensure the GPU runs without I/O interruptions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import sys\n",
                "import time\n",
                "from pathlib import Path\n",
                "from statistics import mean, median\n",
                "import cv2\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "# Set Project Root\n",
                "current_dir = Path.cwd()\n",
                "if current_dir.name == 'testing':\n",
                "    BASE = current_dir.parent\n",
                "else:\n",
                "    BASE = current_dir\n",
                "\n",
                "sys.path.insert(0, str(BASE))\n",
                "print(f'Project Root: {BASE}')\n",
                "\n",
                "from training.helpers.model import MobileNetV3UNetConvLSTMVideo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration\n",
                "- **`TARGET_FPS`**: 33.0 (Real-time target).\n",
                "- **`ROWS/COLS`**: 3x5 tiling grid.\n",
                "- **`VIDEO_FPS`**: 10 (Playback speed for the output video)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --------------------------------------------------------------------\n",
                "# Paths / Config\n",
                "# --------------------------------------------------------------------\n",
                "CHECKPOINT_PATH = BASE / \"training\" / \"checkpoints\" / \"stage2\" / \"best_stage2.pth\"\n",
                "\n",
                "RAINY_DIR = BASE / \"data\" / \"data_crapified_test\" / \"scene_004\" / \"front-forward\"\n",
                "CLEAN_DIR = BASE / \"data\" / \"data_original\" / \"scene_004\" / \"images\" / \"front-forward\"\n",
                "\n",
                "OUTPUT_DIR = BASE / \"test_results\" / \"scene_004_inference_benchmark\"\n",
                "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "TARGET_FPS = 33.0\n",
                "TARGET_MS_PER_FRAME = 1000.0 / TARGET_FPS\n",
                "VIDEO_FPS = 10\n",
                "TILE = 512\n",
                "ROWS, COLS = 3, 5\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimized Helper Functions\n",
                "- **`load_frame_fullres`**: Loads and normalizes images (CPU).\n",
                "- **`make_hann_mask`**: Creates the 2D weighting mask. Note the `periodic=False` for correct windowing.\n",
                "- **`get_tile_coords`**: Computes standard overlapping grid coordinates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_frame_fullres(path: Path) -> torch.Tensor:\n",
                "    img = cv2.imread(str(path))\n",
                "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    return torch.from_numpy(img).permute(2, 0, 1).float().div(255.0)\n",
                "\n",
                "\n",
                "def get_tile_coords(h, w, tile=512, rows=3, cols=5):\n",
                "    xs = np.linspace(0, w - tile, cols).round().astype(int).tolist()\n",
                "    ys = np.linspace(0, h - tile, rows).round().astype(int).tolist()\n",
                "    return [(y, x) for y in ys for x in xs]\n",
                "\n",
                "\n",
                "def make_hann_mask(tile, device):\n",
                "    w1 = torch.hann_window(tile, periodic=False, device=device)\n",
                "    return torch.outer(w1, w1).clamp_min(1e-4).unsqueeze(0)\n",
                "\n",
                "\n",
                "def chw_to_bgr_uint8(chw: torch.Tensor) -> np.ndarray:\n",
                "    return cv2.cvtColor((chw.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Execution\n",
                "\n",
                "### Pipeline Steps:\n",
                "1.  **Setup**: Loads model and pre-calculates tile coordinates.\n",
                "2.  **Pre-Allocation**: Creates `acc_buffer` and `wgt_buffer` on the GPU *before* the loop. This is critical for performance.\n",
                "3.  **Benchmark Loop**:\n",
                "    -   **Load**: Prepare tiles (CPU).\n",
                "    -   **Transfer**: Move tile batch to GPU.\n",
                "    -   **Inference**: Run model (`forward`).\n",
                "    -   **Reconstruct**: Accumulate weighted tiles into the buffers using GPU ops.\n",
                "    -   **Normalize**: Divide accumulation by weight map.\n",
                "4.  **Save Results**: After the timing loop is done, iterate through the buffer to save the video and images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def main():\n",
                "    print(f\"Using device: {device}\")\n",
                "    if not CHECKPOINT_PATH.exists():\n",
                "         raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n",
                "\n",
                "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
                "    model = MobileNetV3UNetConvLSTMVideo(hidden_dim=96, out_channels=3).to(device)\n",
                "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
                "    model.eval()\n",
                "\n",
                "    rainy_files = sorted(RAINY_DIR.glob(\"*.jpeg\"))\n",
                "    clean_files = sorted(CLEAN_DIR.glob(\"*.jpeg\"))\n",
                "    n = min(len(rainy_files), len(clean_files))\n",
                "    if n == 0:\n",
                "        print(\"No frames found!\")\n",
                "        return\n",
                "\n",
                "    # Pre-probe dimensions\n",
                "    tmp_img = cv2.imread(str(rainy_files[0]))\n",
                "    h, w, _ = tmp_img.shape\n",
                "    coords = get_tile_coords(h, w, TILE, ROWS, COLS)\n",
                "    hann_mask = make_hann_mask(TILE, device)\n",
                "\n",
                "    # PRE-ALLOCATE GPU BUFFERS (Critical to prevent fragmentation)\n",
                "    acc_buffer = torch.zeros((3, h, w), device=device)\n",
                "    wgt_buffer = torch.zeros((1, h, w), device=device)\n",
                "\n",
                "    times_ms = []\n",
                "    processed_frames = []\n",
                "\n",
                "    print(f\"\\nStarting Optimized Benchmark ({n} frames)...\")\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for i in range(n):\n",
                "            # 1. Load data (CPU)\n",
                "            rainy_chw = load_frame_fullres(rainy_files[i])\n",
                "            clean_chw = load_frame_fullres(clean_files[i])\n",
                "\n",
                "            # 2. Build Tile Batch\n",
                "            tiles = torch.stack([rainy_chw[:, y:y + TILE, x:x + TILE] for y, x in coords]).to(device)\n",
                "\n",
                "            # --- START TIMING ---\n",
                "            if device.type == \"cuda\": torch.cuda.synchronize()\n",
                "            t0 = time.perf_counter()\n",
                "\n",
                "            # 3. Model Forward\n",
                "            out_tiles = model(tiles.unsqueeze(1)).squeeze(1)\n",
                "\n",
                "            # 4. Weighted Reconstruct (on GPU)\n",
                "            acc_buffer.zero_()\n",
                "            wgt_buffer.zero_()\n",
                "            for idx, (y, x) in enumerate(coords):\n",
                "                tile_out = out_tiles[idx]\n",
                "                acc_buffer[:, y:y + TILE, x:x + TILE].add_(tile_out * hann_mask)\n",
                "                wgt_buffer[:, y:y + TILE, x:x + TILE].add_(hann_mask)\n",
                "\n",
                "            out_full = acc_buffer / wgt_buffer.clamp_min(1e-6)\n",
                "\n",
                "            if device.type == \"cuda\": torch.cuda.synchronize()\n",
                "            dt_ms = (time.perf_counter() - t0) * 1000.0\n",
                "            # --- END TIMING ---\n",
                "\n",
                "            times_ms.append(dt_ms)\n",
                "\n",
                "            # Post-processing (Moving to CPU to free GPU ASAP)\n",
                "            out_cpu = out_full.clamp(0, 1).cpu()\n",
                "            processed_frames.append((rainy_chw, out_cpu, clean_chw, dt_ms))\n",
                "\n",
                "            if i % 10 == 0:\n",
                "                print(f\"Frame {i}/{n}: {dt_ms:.2f}ms ({1000 / dt_ms:.1f} FPS)\")\n",
                "\n",
                "    # --------------------------------------------------------------------\n",
                "    # IO Section (Save results after benchmark is done)\n",
                "    # --------------------------------------------------------------------\n",
                "    print(\"\\nBenchmark finished. Saving video and images...\")\n",
                "    video_path = OUTPUT_DIR / \"comparison_video.mp4\"\n",
                "    writer = cv2.VideoWriter(str(video_path), cv2.VideoWriter_fourcc(*\"mp4v\"), VIDEO_FPS, (w, h * 3))\n",
                "\n",
                "    for i, (r_chw, o_chw, c_chw, dt) in enumerate(processed_frames):\n",
                "        r_bgr = chw_to_bgr_uint8(r_chw)\n",
                "        o_bgr = chw_to_bgr_uint8(o_chw)\n",
                "        c_bgr = chw_to_bgr_uint8(c_chw)\n",
                "\n",
                "        stacked = np.concatenate([r_bgr, o_bgr, c_bgr], axis=0)\n",
                "\n",
                "        # Overlay labels\n",
                "        fps = 1000.0 / dt if dt > 0 else 0\n",
                "        cv2.putText(stacked, f\"{dt:.1f}ms | {fps:.1f} FPS\", (20, 40),\n",
                "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
                "\n",
                "        writer.write(stacked)\n",
                "        if i < 10:  # Only save first few as images to save space\n",
                "            cv2.imwrite(str(OUTPUT_DIR / f\"frame_{i:03d}.png\"), stacked)\n",
                "\n",
                "    writer.release()\n",
                "\n",
                "    # Summary\n",
                "    avg_ms = mean(times_ms)\n",
                "    print(\"\\n\" + \"=\" * 30)\n",
                "    print(f\"AVERAGE LATENCY: {avg_ms:.2f} ms\")\n",
                "    print(f\"AVERAGE FPS:     {1000 / avg_ms:.2f}\")\n",
                "    print(f\"MEETS TARGET:    {avg_ms <= TARGET_MS_PER_FRAME}\")\n",
                "    print(\"=\" * 30)\n",
                "\n",
                "main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
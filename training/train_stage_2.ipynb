{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Stage 2 Training: Fine-Tuning & Perceptual Enhancement\n",
                "\n",
                "## Overview\n",
                "This notebook implements **Stage 2** of the training pipeline. \n",
                "\n",
                "### Goal\n",
                "Stage 2 focuses on fine-tuning the model to produce **visually pleasing** results. We load the weights from the best Stage 1 model and introduce advanced loss functions to sharpen edges and improve perceptual quality.\n",
                "\n",
                "### Key Features\n",
                "- **Initialization**: Loads `best_stage1.pth`.\n",
                "- **Curriculum Learning**: Loss weights are gradually ramped up over time to avoid destabilizing the pre-trained weights:\n",
                "    - **Pixel Loss**: Constant (Alpha=1.0).\n",
                "    - **SSIM Loss**: Ramps up (Beta -> 0.15). Improves structural similarity.\n",
                "    - **Edge Loss**: Ramps up (Gamma -> 0.1). Sharpe's details.\n",
                "    - **Perceptual Loss**: Ramps up (Epsilon -> 0.05). Uses VGG features for realistic textures.\n",
                "- **Scheduler**: `CosineAnnealingLR` for a smooth decay of the learning rate, ideal for fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import time\n",
                "from pathlib import Path\n",
                "import torch\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from torch.amp import autocast, GradScaler\n",
                "\n",
                "# Set Project Root\n",
                "current_dir = Path.cwd()\n",
                "if current_dir.name == 'training':\n",
                "    BASE = current_dir.parent\n",
                "else:\n",
                "    BASE = current_dir\n",
                "\n",
                "sys.path.insert(0, str(BASE))\n",
                "print(f'Project Root: {BASE}')\n",
                "\n",
                "from training.helpers.model import MobileNetV3UNetConvLSTMVideo\n",
                "from training.helpers.dataset import RainRemovalDataset\n",
                "from training.helpers.losses import CombinedVideoLoss"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration\n",
                "\n",
                "Stage 2 uses a lower learning rate and defines the maximum weights for the auxiliary losses.\n",
                "\n",
                "- **`LEARNING_RATE`**: 2e-5 (Lower than Stage 1 to prevent large weight updates).\n",
                "- **`SSIM_MAX`, `EDGE_MAX`, `PERCEPTUAL_MAX`**: The target weights for these losses after the warm-up period."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "CLEAN_DATA = BASE / \"data\" / \"data_original\"\n",
                "RAINY_DATA = BASE / \"data\" / \"data_crapified_train\"\n",
                "CHECKPOINT_DIR = BASE / \"training\" / \"checkpoints\"\n",
                "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "BEST_STAGE1_PATH = CHECKPOINT_DIR / \"stage1\" / \"best_stage1.pth\"\n",
                "\n",
                "# Fine-tuning Hyperparameters (Stage 2)\n",
                "BATCH_SIZE = 64\n",
                "MAX_EPOCHS = 35\n",
                "LEARNING_RATE = 2e-5          # smaller LR for fine-tuning\n",
                "FRAMES_PER_CLIP = 1\n",
                "IMG_SIZE = (512, 512)\n",
                "NUM_WORKERS = 4\n",
                "\n",
                "# Max weights for losses (configurable)\n",
                "SSIM_MAX = 0.15          # beta_max\n",
                "EDGE_MAX = 0.1          # gamma_max\n",
                "PERCEPTUAL_MAX = 0.05    # epsilon_max\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loss Scheduling\n",
                "\n",
                "To ensure stable training, we introduce the complex losses gradually using a ramp-up schedule.\n",
                "- **SSIM**: Ramps up during epochs 1-5.\n",
                "- **Edge Loss**: Ramps up during epochs 11-15.\n",
                "- **Perceptual Loss**: Ramps up during epochs 21-25."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def ramp_weight(epoch_idx: int, start_epoch: int, end_epoch: int, max_value: float) -> float:\n",
                "    \"\"\"\n",
                "    Generic linear ramp for a weight.\n",
                "    Epoch indexing here is 0-based, converted to 1-based inside.\n",
                "    \"\"\"\n",
                "    e = epoch_idx + 1  # 1-based\n",
                "    if e < start_epoch:\n",
                "        return 0.0\n",
                "    if e > end_epoch:\n",
                "        return max_value\n",
                "    # Linear ramp between (start_epoch, end_epoch)\n",
                "    n_increasement_epochs = (end_epoch + 1) - start_epoch\n",
                "    curr_increasement_epoch = (e + 1) - start_epoch\n",
                "    progress = curr_increasement_epoch / float(n_increasement_epochs + 1)\n",
                "    progress = min(1.0, progress)\n",
                "    return max_value * progress\n",
                "\n",
                "\n",
                "def get_current_ssim_weight(epoch_idx: int) -> float:\n",
                "    \"\"\"\n",
                "    SSIM schedule:\n",
                "    - Gradual in epochs 1–5\n",
                "    - MAX at epoch 6+\n",
                "    \"\"\"\n",
                "    return ramp_weight(epoch_idx, start_epoch=1, end_epoch=5, max_value=SSIM_MAX)\n",
                "\n",
                "\n",
                "def get_current_edge_weight(epoch_idx: int) -> float:\n",
                "    \"\"\"\n",
                "    Edge schedule:\n",
                "    - Gradual in epochs 11–15\n",
                "    - MAX at epoch 16+\n",
                "    \"\"\"\n",
                "    return ramp_weight(epoch_idx, start_epoch=11, end_epoch=15, max_value=EDGE_MAX)\n",
                "\n",
                "\n",
                "def get_current_perceptual_weight(epoch_idx: int) -> float:\n",
                "    \"\"\"\n",
                "    Perceptual schedule:\n",
                "    - Gradual in epochs 21–25\n",
                "    - MAX at epoch 26+\n",
                "    \"\"\"\n",
                "    return ramp_weight(epoch_idx, start_epoch=21, end_epoch=25, max_value=PERCEPTUAL_MAX)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Execution\n",
                "\n",
                "The core logic differs from Stage 1 in a few key ways:\n",
                "1.  **Weight Loading**: strictly requires `best_stage1.pth`.\n",
                "2.  **Dynamic Loss**: Inside the loop, `criterion` weights are updated at the start of each epoch based on the schedule.\n",
                "3.  **Checkpointing**: Saves models based on a \"Weighted Loss Metric\" (Pixel + SSIM + Edge + Perceptual) rather than just Pixel loss, ensuring we save the most visually pleasing model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def main():\n",
                "    # ==================== DATASETS ====================\n",
                "    print(\"\\nCreating datasets (Stage 2, per-frame)...\")\n",
                "\n",
                "    train_dataset = RainRemovalDataset(\n",
                "        clean_base_dir=CLEAN_DATA,\n",
                "        rainy_base_dir=RAINY_DATA,\n",
                "        num_scenes=101,\n",
                "        frames_per_clip=FRAMES_PER_CLIP,\n",
                "        consecutive_frames=True,  # ignored in per_frame mode\n",
                "        img_size=IMG_SIZE,\n",
                "        split=\"train\",\n",
                "        train_ratio=0.8,\n",
                "        val_ratio=0.1,\n",
                "        per_frame=True,\n",
                "        random_crop=True,\n",
                "        crop_sizes=[256, 384, 512],\n",
                "        crop_probs=[0.15, 0.25, 0.60],\n",
                "    )\n",
                "\n",
                "    val_dataset = RainRemovalDataset(\n",
                "        clean_base_dir=CLEAN_DATA,\n",
                "        rainy_base_dir=RAINY_DATA,\n",
                "        num_scenes=101,\n",
                "        frames_per_clip=FRAMES_PER_CLIP,\n",
                "        consecutive_frames=True,\n",
                "        img_size=IMG_SIZE,\n",
                "        split=\"val\",\n",
                "        train_ratio=0.8,\n",
                "        val_ratio=0.1,\n",
                "        per_frame=True,\n",
                "        random_crop=True,\n",
                "        crop_sizes=[256, 384, 512],\n",
                "        crop_probs=[0.15, 0.25, 0.60],\n",
                "    )\n",
                "\n",
                "    train_loader = DataLoader(\n",
                "        train_dataset,\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=True,\n",
                "        num_workers=NUM_WORKERS,\n",
                "        pin_memory=True,\n",
                "    )\n",
                "    val_loader = DataLoader(\n",
                "        val_dataset,\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=False,\n",
                "        num_workers=NUM_WORKERS,\n",
                "        pin_memory=True,\n",
                "    )\n",
                "\n",
                "    print(f\"Train samples:  {len(train_dataset)}  -> batches: {len(train_loader)}\")\n",
                "    print(f\"Val samples:    {len(val_dataset)}    -> batches: {len(val_loader)}\")\n",
                "\n",
                "    # ==================== MODEL ====================\n",
                "    print(\"\\nInitializing model for Stage 2 (fine-tuning from best_stage1)...\")\n",
                "\n",
                "    if not BEST_STAGE1_PATH.exists():\n",
                "        raise FileNotFoundError(\n",
                "            f\"Cannot find {BEST_STAGE1_PATH}. \"\n",
                "            f\"Train Stage 1 first to produce best_stage1.pth.\"\n",
                "        )\n",
                "\n",
                "    model = MobileNetV3UNetConvLSTMVideo(\n",
                "        hidden_dim=96,\n",
                "        out_channels=3,\n",
                "        use_pretrained_encoder=True,\n",
                "        freeze_encoder=True,  # keep encoder frozen for sharpening\n",
                "    ).to(device)\n",
                "\n",
                "    # Initialize lazy layers\n",
                "    print(\"Initializing lazy layers...\")\n",
                "    with torch.no_grad():\n",
                "        dummy = torch.randn(1, FRAMES_PER_CLIP, 3, IMG_SIZE[0], IMG_SIZE[1]).to(device)\n",
                "        _ = model(dummy)\n",
                "        del dummy\n",
                "    print(\"✓ Lazy layers initialized\")\n",
                "\n",
                "    # Load Stage-1 checkpoint weights\n",
                "    print(f\"Loading weights from: {BEST_STAGE1_PATH}\")\n",
                "    ckpt = torch.load(BEST_STAGE1_PATH, map_location=device)\n",
                "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
                "    print(\"✓ Weights loaded from Stage 1\\n\")\n",
                "\n",
                "    model.print_param_summary()\n",
                "\n",
                "    # ==================== LOSS ====================\n",
                "    # Start with only pixel loss; other weights will be updated every epoch.\n",
                "    criterion = CombinedVideoLoss(\n",
                "        alpha=1.0,   # pixel (Charbonnier)\n",
                "        beta=0.0,    # SSIM (will ramp to SSIM_MAX)\n",
                "        gamma=0.0,   # Edge (will ramp to EDGE_MAX)\n",
                "        delta=0.0,   # Temporal OFF\n",
                "        epsilon=0.0  # Perceptual (will ramp to PERCEPTUAL_MAX)\n",
                "    ).to(device)\n",
                "\n",
                "    print(\"Using CombinedVideoLoss (Stage 2 fine-tuning):\")\n",
                "    print(f\"  alpha (pixel):        {criterion.alpha}\")\n",
                "    print(f\"  beta  (SSIM)  max:    {SSIM_MAX}\")\n",
                "    print(f\"  gamma (edge)  max:    {EDGE_MAX}\")\n",
                "    print(f\"  epsilon (percept.) max:{PERCEPTUAL_MAX}\")\n",
                "    print(f\"  delta (temporal):     {criterion.delta}\\n\")\n",
                "\n",
                "    # ==================== OPTIMIZER & SCHEDULER ====================\n",
                "    optimizer = optim.Adam(\n",
                "        filter(lambda p: p.requires_grad, model.parameters()),\n",
                "        lr=LEARNING_RATE,\n",
                "    )\n",
                "\n",
                "    # Cosine annealing over the full 35 epochs – common for fine-tuning\n",
                "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
                "        optimizer,\n",
                "        T_max=MAX_EPOCHS,\n",
                "        eta_min=5e-6,\n",
                "    )\n",
                "\n",
                "    scaler = GradScaler(\"cuda\")\n",
                "\n",
                "    # We track \"best\" using the fixed max-weight metric:\n",
                "    # total_max = pixel + SSIM_MAX * ssim + EDGE_MAX * edge + PERCEPTUAL_MAX * perceptual\n",
                "    best_val_loss = float(\"inf\")\n",
                "    best_epoch = 0\n",
                "\n",
                "    train_losses = []\n",
                "    val_losses = []\n",
                "\n",
                "    print(\"=\" * 60)\n",
                "    print(\"STARTING STAGE 2 FINE-TUNING (PIXEL + SSIM + EDGE + PERCEPTUAL)\")\n",
                "    print(\"=\" * 60)\n",
                "\n",
                "    for epoch in range(MAX_EPOCHS):\n",
                "        epoch_start = time.time()\n",
                "        epoch_num = epoch + 1\n",
                "\n",
                "        # ----- Update loss weights for this epoch -----\n",
                "        current_beta = get_current_ssim_weight(epoch)\n",
                "        current_gamma = get_current_edge_weight(epoch)\n",
                "        current_epsilon = get_current_perceptual_weight(epoch)\n",
                "\n",
                "        criterion.beta = current_beta\n",
                "        criterion.gamma = current_gamma\n",
                "        criterion.epsilon = current_epsilon\n",
                "\n",
                "        print(\n",
                "            f\"\\nEpoch {epoch_num}/{MAX_EPOCHS} \"\n",
                "            f\"(beta/SSIM={current_beta:.4f}, \"\n",
                "            f\"gamma/Edge={current_gamma:.4f}, \"\n",
                "            f\"epsilon/Perc={current_epsilon:.4f})\"\n",
                "        )\n",
                "\n",
                "        # -------------------- TRAIN --------------------\n",
                "        model.train()\n",
                "        running_train_loss_max = 0.0\n",
                "\n",
                "        for batch_idx, (rainy, clean) in enumerate(train_loader):\n",
                "            rainy = rainy.to(device)   # (B, 1, 3, H, W)\n",
                "            clean = clean.to(device)   # (B, 1, 3, H, W)\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "\n",
                "            with autocast(\"cuda\"):\n",
                "                output = model(rainy)\n",
                "                loss, loss_dict = criterion(output, clean)\n",
                "\n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "\n",
                "            # --- Metric with final max weights (for curves/checkpoints) ---\n",
                "            pixel_loss = loss_dict[\"pixel\"]\n",
                "            ssim_loss = loss_dict[\"ssim\"]\n",
                "            edge_loss = loss_dict[\"edge\"]\n",
                "            perc_loss = loss_dict[\"perceptual\"]\n",
                "\n",
                "            total_max = (\n",
                "                1.0 * pixel_loss\n",
                "                + SSIM_MAX * ssim_loss\n",
                "                + EDGE_MAX * edge_loss\n",
                "                + PERCEPTUAL_MAX * perc_loss\n",
                "            )\n",
                "\n",
                "            running_train_loss_max += float(total_max)\n",
                "\n",
                "            if (batch_idx + 1) % 100 == 0:\n",
                "                print(\n",
                "                    f\"  Batch [{batch_idx + 1}/{len(train_loader)}] \"\n",
                "                    f\"Total(curr): {loss_dict['total']:.4f} | \"\n",
                "                    f\"Pixel: {pixel_loss:.4f} | \"\n",
                "                    f\"SSIM: {ssim_loss:.4f} | \"\n",
                "                    f\"Edge: {edge_loss:.4f} | \"\n",
                "                    f\"Perc: {perc_loss:.4f}\"\n",
                "                )\n",
                "\n",
                "        train_loss = running_train_loss_max / len(train_loader)\n",
                "        train_losses.append(train_loss)\n",
                "\n",
                "        # -------------------- VALIDATION --------------------\n",
                "        model.eval()\n",
                "        running_val_loss_max = 0.0\n",
                "\n",
                "        with torch.no_grad():\n",
                "            for rainy, clean in val_loader:\n",
                "                rainy = rainy.to(device)\n",
                "                clean = clean.to(device)\n",
                "                with autocast(\"cuda\"):\n",
                "                    output = model(rainy)\n",
                "                    loss, loss_dict = criterion(output, clean)\n",
                "\n",
                "                # Same fixed max-weight metric as in train\n",
                "                pixel_loss = loss_dict[\"pixel\"]\n",
                "                ssim_loss = loss_dict[\"ssim\"]\n",
                "                edge_loss = loss_dict[\"edge\"]\n",
                "                perc_loss = loss_dict[\"perceptual\"]\n",
                "\n",
                "                total_max = (\n",
                "                    1.0 * pixel_loss\n",
                "                    + SSIM_MAX * ssim_loss\n",
                "                    + EDGE_MAX * edge_loss\n",
                "                    + PERCEPTUAL_MAX * perc_loss\n",
                "                )\n",
                "\n",
                "                running_val_loss_max += float(total_max)\n",
                "\n",
                "        val_loss = running_val_loss_max / len(val_loader)\n",
                "        val_losses.append(val_loss)\n",
                "\n",
                "        # Step LR scheduler (epoch-wise)\n",
                "        scheduler.step()\n",
                "\n",
                "        epoch_time = time.time() - epoch_start\n",
                "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
                "\n",
                "        print(\"\\n\" + \"-\" * 60)\n",
                "        print(f\"Epoch [{epoch_num}/{MAX_EPOCHS}] completed\")\n",
                "        print(f\"Train Loss (max-weight metric): {train_loss:.6f}\")\n",
                "        print(f\"Val   Loss (max-weight metric): {val_loss:.6f}\")\n",
                "        print(f\"Time:       {epoch_time:.1f}s\")\n",
                "        print(f\"LR:         {current_lr:.6f}\")\n",
                "        print(\n",
                "            f\"Weights -> alpha:1.0  beta/SSIM:{criterion.beta:.4f}  \"\n",
                "            f\"gamma/Edge:{criterion.gamma:.4f}  epsilon/Perc:{criterion.epsilon:.4f}\"\n",
                "        )\n",
                "        print(\"-\" * 60 + \"\\n\")\n",
                "\n",
                "        # -------------------- CHECKPOINTING --------------------\n",
                "        checkpoint = {\n",
                "            \"epoch\": epoch_num,\n",
                "            \"model_state_dict\": model.state_dict(),\n",
                "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
                "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
                "            \"scaler_state_dict\": scaler.state_dict(),\n",
                "            # Final-weights loss metrics:\n",
                "            \"train_loss\": train_loss,\n",
                "            \"val_loss\": val_loss,\n",
                "            \"train_losses\": train_losses,\n",
                "            \"val_losses\": val_losses,\n",
                "            \"beta_ssim\": criterion.beta,\n",
                "            \"gamma_edge\": criterion.gamma,\n",
                "            \"epsilon_perceptual\": criterion.epsilon,\n",
                "            \"SSIM_MAX\": SSIM_MAX,\n",
                "            \"EDGE_MAX\": EDGE_MAX,\n",
                "            \"PERCEPTUAL_MAX\": PERCEPTUAL_MAX,\n",
                "            \"batch_size\": BATCH_SIZE,\n",
                "        }\n",
                "\n",
                "        # latest Stage 2\n",
                "        torch.save(checkpoint, CHECKPOINT_DIR / \"stage2\" / \"latest_stage2.pth\")\n",
                "\n",
                "        # best Stage 2 – based on max-weight val_loss\n",
                "        if val_loss < best_val_loss:\n",
                "            best_val_loss = val_loss\n",
                "            best_epoch = epoch_num\n",
                "            torch.save(checkpoint, CHECKPOINT_DIR / \"stage2\" / \"best_stage2.pth\")\n",
                "            print(f\"✓ New best Stage-2 model saved \"\n",
                "                  f\"(val_loss={val_loss:.6f} at epoch {epoch_num})\\n\")\n",
                "        \n",
                "        # extra snapshots (every 5 epochs)\n",
                "        if epoch_num % 5 == 0:\n",
                "            torch.save(\n",
                "                checkpoint,\n",
                "                CHECKPOINT_DIR / \"stage2\" / f\"stage2_epoch_{epoch_num}.pth\"\n",
                "            )\n",
                "\n",
                "    print(\"=\" * 60)\n",
                "    print(\"STAGE 2 FINE-TUNING COMPLETE\")\n",
                "    print(\"=\" * 60)\n",
                "    print(f\"Best validation loss (max-weight metric): {best_val_loss:.6f}\")\n",
                "    print(f\"Best epoch: {best_epoch}\")\n",
                "    print(f\"Checkpoints saved in: {CHECKPOINT_DIR}\")\n",
                "\n",
                "main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}